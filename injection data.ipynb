{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ab3e59",
   "metadata": {},
   "source": [
    "## Test lecture data sur S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4db6fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be75ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nom du bucket et chemin du fichier\n",
    "bucket_name = \"david-mlops-bucket\"\n",
    "fichier_s3  = \"s3://david-mlops-bucket/conso grdf/Donnees_informatives_02269609199626_2025-10-13_2025-10-20_68f65c45bfe56.xlsx\"\n",
    "\n",
    "import awswrangler as wr\n",
    "\n",
    "#s3_path = 's3://votre-bucket/chemin/vers/votre/fichier.xlsx'\n",
    "#df = wr.s3.read_excel(path=fichier_s3 , sheet_name=0, skiprows=8,usecols=\"B:H\") # sheet_name=0 pour la première feuille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d8acc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def lister_fichiers_excel_s3():\n",
    "    \"\"\"\n",
    "    Récupère la liste des fichiers Excel (.xlsx, .xls) dans un bucket S3.\n",
    "\n",
    "    :return: Une liste des clés (noms de chemins) des fichiers Excel.\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    bucket_name   = os.environ.get(\"NOM_DU_BUCKET\")\n",
    "    prefix        = os.environ.get(\"PREFIXE_DOSSIER\")  \n",
    "\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id     = os.environ.get(\"aws_access_key_id\"),\n",
    "        aws_secret_access_key = os.environ.get(\"aws_secret_access_key\")\n",
    "    )\n",
    "\n",
    "    \n",
    "    excel_files = []\n",
    "    \n",
    "    # Pour gérer un grand nombre de fichiers (pagination)\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "    for page in pages:\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                key = obj['Key']\n",
    "                # Filtrer par extension\n",
    "                if key.lower().endswith('.xlsx') or key.lower().endswith('.xls'):                    \n",
    "                    excel_files.append(f\"s3://{bucket_name}/{key}\")\n",
    "                    \n",
    "    return excel_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b76ff789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "liste_excel = lister_fichiers_excel_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da6cb97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://david-mlops-bucket/conso grdf/Donnees_informatives_02269609199626_2025-10-13_2025-10-20_68f65c45bfe56.xlsx']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03b7195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://david-mlops-bucket/conso grdf/Donnees_informatives_02269609199626_2025-10-13_2025-10-20_68f65c45bfe56.xlsx'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fichier_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac7907f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lire_fichier_excel_s3(fichier_s3):\n",
    "\n",
    "    import boto3\n",
    "\n",
    "\n",
    "    import awswrangler as wr\n",
    "\n",
    "    # Créez une session boto3 avec vos identifiants\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=os.environ.get(\"aws_access_key_id\"),\n",
    "        aws_secret_access_key=os.environ.get(\"aws_secret_access_key\")\n",
    "    )\n",
    "\n",
    "    # Remplacez par le chemin exact de votre fichier\n",
    "    #fichier_s3 = \"s3://david-mlops-bucket/conso grdf/Donnees_informatives_02269609199626_2025-10-13_2025-10-20_68f65c45bfe56.xlsx\"\n",
    "\n",
    "    try:\n",
    "        # Lisez le fichier Excel avec awswrangler\n",
    "        df = wr.s3.read_excel(\n",
    "            path=fichier_s3,\n",
    "            boto3_session=session,\n",
    "            sheet_name=0,\n",
    "            skiprows=8,\n",
    "            usecols=\"B:H\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur inattendue : {e}\")\n",
    "        df = None\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40b699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Récupérer les variables d'environnement avec des valeurs par défaut\n",
    "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"conso\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a5ebc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Labrax_007'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44fe0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data_jour_gaz_from_s3():\n",
    "    import pandas as pd\n",
    "\n",
    "    liste_excel = lister_fichiers_excel_s3()\n",
    "    list_df = list()\n",
    "\n",
    "    for f in liste_excel:\n",
    "        print(f\"Lecture du fichier : {f}\")\n",
    "        df = lire_fichier_excel_s3(f)\n",
    "        list_df.append(df)\n",
    "    \n",
    "    df_newdata_gaz = pd.concat(list_df)\n",
    "    df_newdata_gaz = df_newdata_gaz[['Date de relevé', 'Volume consommé (m3)', 'Energie consommée (kWh)', 'Coefficient de conversion', 'Température locale (°C)']]\n",
    "    df_newdata_gaz.columns = ['horodatage', 'volume', 'energie','pci','text']\n",
    "\n",
    "\n",
    "    return df_newdata_gaz\n",
    "\n",
    "def lire_fichier_excel_s3(fichier_s3):\n",
    "\n",
    "    import boto3\n",
    "    import os\n",
    "    import awswrangler as wr\n",
    "\n",
    "    # Créez une session boto3 avec vos identifiants\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=os.environ.get(\"aws_access_key_id\"),\n",
    "        aws_secret_access_key=os.environ.get(\"aws_secret_access_key\")\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Lisez le fichier Excel avec awswrangler\n",
    "        df = wr.s3.read_excel(\n",
    "            path=fichier_s3,\n",
    "            boto3_session=session,\n",
    "            sheet_name=0,\n",
    "            skiprows=8,\n",
    "            usecols=\"B:H\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur inattendue : {e}\")\n",
    "        df = None\n",
    "\n",
    "    return df    \n",
    "\n",
    "def lister_fichiers_excel_s3():\n",
    "    \"\"\"\n",
    "    Récupère la liste des fichiers Excel (.xlsx, .xls) dans un bucket S3.\n",
    "\n",
    "    :return: Une liste des clés (noms de chemins) des fichiers Excel.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import boto3\n",
    "\n",
    "    bucket_name   = os.environ.get(\"NOM_DU_BUCKET\")\n",
    "    prefix        = os.environ.get(\"PREFIXE_DOSSIER\")  \n",
    "\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        aws_access_key_id     = os.environ.get(\"aws_access_key_id\"),\n",
    "        aws_secret_access_key = os.environ.get(\"aws_secret_access_key\")\n",
    "    )\n",
    "\n",
    "    \n",
    "    excel_files = []\n",
    "    \n",
    "    # Pour gérer un grand nombre de fichiers (pagination)\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "    for page in pages:\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                key = obj['Key']\n",
    "                # Filtrer par extension\n",
    "                if key.lower().endswith('.xlsx') or key.lower().endswith('.xls'):                    \n",
    "                    excel_files.append(f\"s3://{bucket_name}/{key}\")\n",
    "                    \n",
    "    return excel_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eca6a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture du fichier : s3://david-mlops-bucket/conso grdf/Donnees_informatives_02269609199626_2025-10-13_2025-10-20_68f65c45bfe56.xlsx\n"
     ]
    }
   ],
   "source": [
    "df = get_data_jour_gaz_from_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53081964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horodatage']=pd.to_datetime(df['horodatage'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b56efaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horodatage</th>\n",
       "      <th>volume</th>\n",
       "      <th>energie</th>\n",
       "      <th>pci</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-13</td>\n",
       "      <td>2.90</td>\n",
       "      <td>32.85</td>\n",
       "      <td>11.33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>1.16</td>\n",
       "      <td>13.14</td>\n",
       "      <td>11.33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2.23</td>\n",
       "      <td>25.26</td>\n",
       "      <td>11.33</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-16</td>\n",
       "      <td>2.86</td>\n",
       "      <td>32.40</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-17</td>\n",
       "      <td>2.77</td>\n",
       "      <td>31.38</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-10-18</td>\n",
       "      <td>3.28</td>\n",
       "      <td>36.93</td>\n",
       "      <td>11.26</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horodatage  volume  energie    pci  text\n",
       "0 2025-10-13    2.90    32.85  11.33   NaN\n",
       "1 2025-10-14    1.16    13.14  11.33   NaN\n",
       "2 2025-10-15    2.23    25.26  11.33  13.0\n",
       "3 2025-10-16    2.86    32.40  11.33  11.0\n",
       "4 2025-10-17    2.77    31.38  11.33  11.0\n",
       "5 2025-10-18    3.28    36.93  11.26  11.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185e1593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_URL: postgresql://postgres:Labrax_007@localhost:5432/conso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_8672\\2472035706.py:33: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.exc import IntegrityError\n",
    "import logging\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "from datetime import datetime\n",
    "from sqlalchemy import Column, Integer, Float, TIMESTAMP, UniqueConstraint\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import os\n",
    "\n",
    "# Récupérer les variables d'environnement avec des valeurs par défaut\n",
    "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"conso\")\n",
    "\n",
    "\n",
    "# Construire l'URL de connexion à la base de données\n",
    "DB_URL = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "print(f\"DB_URL: {DB_URL}\")  # Ajout d'un print pour débogage\n",
    "\n",
    "# Créer l'engin SQLAlchemy\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "# Créer une session locale\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "db = SessionLocal()\n",
    "# Base pour les modèles\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dd94a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app.crud:6 lignes insérées ou mises à jour avec succès sur les données gaz jours.\n"
     ]
    }
   ],
   "source": [
    "from app.crud import insert_data_conso_gaz_jour\n",
    "\n",
    "insert_data_conso_gaz_jour(db, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ab51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data_horaire_from_api():\n",
    "\n",
    "    \"\"\"\n",
    "    Récupère les données de consommation au pas de temps demie-heure pour un compteur (PRM)\n",
    "    entre les dates start (incluse) et end (exclue).\n",
    "    \n",
    "    :param start: date de début au format 'YYYY-MM-DD'\n",
    "    :param end: date de fin (non incluse) au format 'YYYY-MM-DD'\n",
    "    :return: réponse JSON si succès, sinon lève une exception\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "    import os\n",
    "    import logging\n",
    "    import requests\n",
    "\n",
    "\n",
    "    # Récupérer les variables d'environnement avec des valeurs par défaut\n",
    "\n",
    "    API_TOKEN = os.environ.get(\"API_TOKEN\", \"\")\n",
    "    PRM       = os.environ.get(\"PRM_ELEC\", \"\")\n",
    "\n",
    "    today_tstamp = datetime.now()\n",
    "    day_start_import_tstamp = (today_tstamp - timedelta(days=2))\n",
    "\n",
    "    today_str = today_tstamp.strftime('%Y-%m-%d')\n",
    "    day_start_import_str = day_start_import_tstamp.strftime('%Y-%m-%d') \n",
    "\n",
    "\n",
    "    base_url = \"https://conso.boris.sh/api/consumption_load_curve\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "        \"User-Agent\": \"MonApp/1.0 (contact@example.com)\"  # optionnel mais recommandé\n",
    "    }\n",
    "    params = {\n",
    "        \"prm\": PRM,\n",
    "        \"start\": day_start_import_str,\n",
    "        \"end\": today_str\n",
    "    }\n",
    "    \n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "    # Vérifier le code HTTP\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Erreur HTTP {response.status_code} : {response.text}\")\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a0055bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'horodatage': Timestamp('2025-10-19 00:00:00'), 'value': 32.286638297872344},\n",
       " {'horodatage': Timestamp('2025-10-20 00:00:00'), 'value': 21.981},\n",
       " {'horodatage': Timestamp('2025-10-21 00:00:00'), 'value': 11.184000000000001}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dca89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_URL: postgresql://postgres:Labrax_007@localhost:5432/conso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_8672\\1930780979.py:33: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "import logging\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "from datetime import datetime\n",
    "from sqlalchemy import Column, Integer, Float, TIMESTAMP, UniqueConstraint\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import os\n",
    "\n",
    "# Récupérer les variables d'environnement avec des valeurs par défaut\n",
    "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"conso\")\n",
    "\n",
    "\n",
    "# Construire l'URL de connexion à la base de données\n",
    "DB_URL = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "print(f\"DB_URL: {DB_URL}\")  # Ajout d'un print pour débogage\n",
    "\n",
    "# Créer l'engin SQLAlchemy\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "# Créer une session locale\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "db = SessionLocal()\n",
    "# Base pour les modèles\n",
    "Base = declarative_base()\n",
    "\n",
    "class ConsoJourElec(Base):\n",
    "    __tablename__ = \"conso_jour_elec\"\n",
    "\n",
    "\n",
    "    horodatage = Column(TIMESTAMP, nullable=False, primary_key=True)\n",
    "    value = Column(Float, nullable=False)\n",
    "\n",
    "    __table_args__ = (\n",
    "        UniqueConstraint(\"horodatage\", name=\"conso_jour_elec_horodatage_key\"),\n",
    "    )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<ConsoJourElec(horodatage={self.horodatage}, value={self.value})>\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Upsert (INSERT or UPDATE)\n",
    "try:\n",
    "    stmt = insert(ConsoJourElec).values(data_to_insert)\n",
    "\n",
    "\n",
    "    stmt = stmt.on_conflict_do_update(\n",
    "    constraint=\"conso_jour_elec_horodatage_key\",  # <-- utiliser le nom de la contrainte UNIQUE\n",
    "    set_={\"value\": stmt.excluded.value})\n",
    "\n",
    "    db.execute(stmt)\n",
    "    db.commit()\n",
    "\n",
    "except IntegrityError as e:\n",
    "    db.rollback()\n",
    "    print(f\"IntegrityError: {e}\")\n",
    "except Exception as e:\n",
    "    db.rollback()\n",
    "    print(f\"Erreur inattendue: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59befe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Récupération de la liste des fichiers Excel dans un bucket S3\n",
    "\n",
    "\n",
    "liste_excel = lister_fichiers_excel_s3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d776ebb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conso grdf/Donnees_informatives_02269609199626_2025-10-13_2025-10-20_68f65c45bfe56.xlsx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362499ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion à la base de données réussie.\n",
      "Données importées avec succès !\n",
      "Connexion fermée.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Chemin vers ton fichier CSV sur EC2\n",
    "csv_file_path = \"data/conso_jour_gaz.csv\"\n",
    "\n",
    "# Nom de la table dans PostgreSQL\n",
    "table_name = \"conso_jour_gaz\"\n",
    "\n",
    "\n",
    "# Configuration de la connexion à la base de données RDS\n",
    "db_config = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"conso\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Labrax_007\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def import_csv_to_postgresql(conn, csv_file_path):\n",
    "    with conn.cursor() as cursor:\n",
    "        with open(csv_file_path, \"r\") as f:\n",
    "            # Ignore la première ligne (en-tête)\n",
    "            next(f)\n",
    "            # Utilise une table temporaire pour éviter les conflits\n",
    "            cursor.execute(\n",
    "                sql.SQL(\"\"\"\n",
    "                    CREATE TEMP TABLE temp_import AS\n",
    "                    SELECT * FROM {} LIMIT 0\n",
    "                \"\"\").format(sql.Identifier(table_name))\n",
    "            )\n",
    "            # Import dans la table temporaire\n",
    "            cursor.copy_expert(\n",
    "                sql.SQL(\"\"\"\n",
    "                    COPY temp_import (horodatage,volume,energie,pci,text)\n",
    "                    FROM STDIN\n",
    "                    WITH (FORMAT csv, DELIMITER ',')\n",
    "                \"\"\"),\n",
    "                f,\n",
    "            )\n",
    "            # Insère les données en ignorant les doublons\n",
    "            cursor.execute(\n",
    "                sql.SQL(\"\"\"\n",
    "                    INSERT INTO {}\n",
    "                    (horodatage,volume,energie,pci,text)\n",
    "                    SELECT horodatage,volume,energie,pci,text FROM temp_import\n",
    "                    ON CONFLICT (horodatage) DO NOTHING\n",
    "                \"\"\").format(sql.Identifier(table_name))\n",
    "            )\n",
    "        conn.commit()\n",
    "\n",
    "# Connexion à la base de données et exécution\n",
    "try:\n",
    "    conn = psycopg2.connect(**db_config)\n",
    "    print(\"Connexion à la base de données réussie.\")\n",
    "    import_csv_to_postgresql(conn, csv_file_path)\n",
    "    print(\"Données importées avec succès !\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur : {e}\")\n",
    "finally:\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "        print(\"Connexion fermée.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
